{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scraping wayback machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to make url list given cdx wayback api query with date range\n",
    "def make_link_list(cdx_url):\n",
    "    urls = rq.get(cdx_url).text\n",
    "    parse_url = json.loads(urls)\n",
    "    \n",
    "    url_list = []\n",
    "    \n",
    "    for i in range(1, len(parse_url)):\n",
    "        orig_url = parse_url[i][2]\n",
    "        tstamp = parse_url[i][1]\n",
    "        waylink = tstamp+'/'+orig_url\n",
    "        url_list.append(waylink)\n",
    "    return(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url_list):\n",
    "    # compiles final url pattern\n",
    "    song_data = []\n",
    "    reqs = 0\n",
    "    start_time = time.time()\n",
    "#     df = pd.DataFrame(columns = ['title', 'artist'])\n",
    "\n",
    "    for url in url_list:\n",
    "\n",
    "        final_url = 'https://web.archive.org/web/'+url\n",
    "\n",
    "        try:\n",
    "            req=rq.get(final_url).text\n",
    "        except urllib.error.URLError as e:\n",
    "            print('Error: {}'.format(e.reason))\n",
    "\n",
    "        sleep(randint(10,20))\n",
    "        reqs += 1\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print('Request: {}; Freq: {} requests/s'.format(reqs, reqs/elapsed_time))\n",
    "\n",
    "        if reqs > len(url_07):\n",
    "            warn('No. of requests was greater than expected')\n",
    "            break\n",
    "\n",
    "        soup = bs(req,'html.parser')\n",
    "        song_rows = soup.find_all(\"tr\", {\"height\": 32})\n",
    "        songs = [i.find_all(\"td\")[1].text.split(\"\\n\") for i in song_rows]\n",
    "#         df.append(songs)\n",
    "        song_data.append(songs)\n",
    "    return song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tracks(song_list, df):\n",
    "    for day in song_list:\n",
    "        for song in day:\n",
    "            df.loc[len(df)] = song\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2003 Requests \n",
    "-- doesnt work -- inspect page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1; Freq: 0.0759792506539738 requests/s\n",
      "Request: 2; Freq: 0.08043740894213708 requests/s\n",
      "Request: 3; Freq: 0.08120632068264073 requests/s\n",
      "Request: 4; Freq: 0.07431234284351056 requests/s\n",
      "Request: 5; Freq: 0.07417854401800088 requests/s\n"
     ]
    }
   ],
   "source": [
    "# set up url list\n",
    "url_03 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20030101&to=20031231&output=json\"\n",
    "url_03_list = make_link_list(url_03)\n",
    "# get songs with list\n",
    "songs_03 = get_data(url_03_list)\n",
    "# make df to hold songs\n",
    "df_03 = pd.DataFrame(columns=['title', 'artist'])\n",
    "# add songs to df\n",
    "get_tracks(songs_03, df_03)\n",
    "#clean data\n",
    "df_03['artist'] = df_03['artist'].str.replace(\" - tour dates\", \"\")\n",
    "df_03['artist'] = df_03['artist'].str.strip()\n",
    "#to_csv\n",
    "df_03.to_csv('./data/2003.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], []]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2004 Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1; Freq: 0.08643170103145895 requests/s\n",
      "Request: 2; Freq: 0.07575947546380553 requests/s\n",
      "Request: 3; Freq: 0.06938629349023696 requests/s\n",
      "Request: 4; Freq: 0.07185897969229359 requests/s\n",
      "Request: 5; Freq: 0.07089525981523594 requests/s\n",
      "Request: 6; Freq: 0.06638594180614492 requests/s\n",
      "Request: 7; Freq: 0.06619665532756273 requests/s\n",
      "Request: 8; Freq: 0.06814396413713458 requests/s\n",
      "Request: 9; Freq: 0.06524748784266371 requests/s\n",
      "Request: 10; Freq: 0.06350945660479193 requests/s\n",
      "Request: 11; Freq: 0.06285580242446442 requests/s\n",
      "Request: 12; Freq: 0.06321656774895619 requests/s\n",
      "Request: 13; Freq: 0.06417424496735202 requests/s\n",
      "Request: 14; Freq: 0.06372972919669545 requests/s\n",
      "Request: 15; Freq: 0.06311865695448322 requests/s\n"
     ]
    }
   ],
   "source": [
    "# set up url list\n",
    "url_04 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20040101&to=20041231&output=json\"\n",
    "url_04_list = make_link_list(url_04)\n",
    "# get songs with list\n",
    "songs_04 = get_data(url_04_list)\n",
    "# make df to hold songs\n",
    "df_04 = pd.DataFrame(columns=['title', 'artist'])\n",
    "# add songs to df\n",
    "get_tracks(songs_04, df_04)\n",
    "#clean data\n",
    "df_04['artist'] = df_04['artist'].str.replace(\" - tour dates\", \"\")\n",
    "df_04['artist'] = df_04['artist'].str.strip()\n",
    "#to_csv\n",
    "df_04.to_csv('./data/2004.cvs', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2005 Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1; Freq: 0.04800416875801764 requests/s\n",
      "Request: 2; Freq: 0.04793270206136535 requests/s\n",
      "Request: 3; Freq: 0.05146648607664957 requests/s\n",
      "Request: 4; Freq: 0.05376406516909134 requests/s\n",
      "Request: 5; Freq: 0.057025714560563046 requests/s\n",
      "Request: 6; Freq: 0.05571483545943099 requests/s\n",
      "Request: 7; Freq: 0.0553112444634199 requests/s\n",
      "Request: 8; Freq: 0.05780302216748713 requests/s\n",
      "Request: 9; Freq: 0.060207914795894935 requests/s\n",
      "Request: 10; Freq: 0.060096445626386726 requests/s\n",
      "Request: 11; Freq: 0.061778209728820775 requests/s\n",
      "Request: 12; Freq: 0.06046888883706278 requests/s\n",
      "Request: 13; Freq: 0.060876592192491245 requests/s\n",
      "Request: 14; Freq: 0.0601342850283886 requests/s\n",
      "Request: 15; Freq: 0.06150912893268427 requests/s\n",
      "Request: 16; Freq: 0.06246518398287905 requests/s\n",
      "Request: 17; Freq: 0.06303318662184423 requests/s\n",
      "Request: 18; Freq: 0.06259496943832596 requests/s\n",
      "Request: 19; Freq: 0.06240558507343293 requests/s\n",
      "Request: 20; Freq: 0.06180055729114726 requests/s\n",
      "Request: 21; Freq: 0.060992773086598624 requests/s\n",
      "Request: 22; Freq: 0.060293785155214004 requests/s\n",
      "Request: 23; Freq: 0.06072776271697019 requests/s\n",
      "Request: 24; Freq: 0.059773401726995835 requests/s\n"
     ]
    }
   ],
   "source": [
    "# set up url list\n",
    "url_05 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20050101&to=20051231&output=json\"\n",
    "url_05_list = make_link_list(url_05)\n",
    "# get songs with list\n",
    "songs_05 = get_data(url_05_list)\n",
    "# make df to hold songs\n",
    "df_05 = pd.DataFrame(columns=['title', 'artist'])\n",
    "# add songs to df\n",
    "get_tracks(songs_05, df_05)\n",
    "#clean data\n",
    "df_05['artist'] = df_05['artist'].str.replace(\" - tour dates\", \"\")\n",
    "df_05['artist'] = df_05['artist'].str.strip()\n",
    "#to_csv\n",
    "df_05.to_csv('./data/2005.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2006 Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_06 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20060101&to=20061231&output=json\"\n",
    "url_06_list = make_link_list(url_06)\n",
    "\n",
    "songs_06 = get_data(url_06_list)\n",
    "\n",
    "df_06 = pd.DataFrame(columns=['title', 'artist'])\n",
    "\n",
    "get_tracks(songs_06, df_06)\n",
    "\n",
    "df_06['artist'] = df_06['artist'].str.replace(\" - tour dates\", \"\")\n",
    "\n",
    "df_06['artist'] = df_06['artist'].str.strip()\n",
    "\n",
    "df_06.to_csv('./data/2006.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2007 Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_07 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20070101&to=20071231&output=json\"\n",
    "\n",
    "url_07_list = make_link_list(url_07)\n",
    "\n",
    "# compiles final url pattern\n",
    "song_data_07 = []\n",
    "reqs = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for url in url_07_list:\n",
    "    \n",
    "    final_url_07 = 'https://web.archive.org/web/'+url\n",
    "    \n",
    "    try:\n",
    "        req=rq.get(final_url_07).text\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Error: {}'.format(e.reason))\n",
    "        \n",
    "    sleep(randint(10,20))\n",
    "    reqs += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Request: {}; Freq: {} requests/s'.format(reqs, reqs/elapsed_time))\n",
    "    \n",
    "    if reqs > len(url_07_list):\n",
    "        warn('No. of requests was greater than expected')\n",
    "        break\n",
    "    \n",
    "    soup = bs(req,'html.parser')\n",
    "    song_rows = soup.find_all(\"tr\", {\"height\": 32})\n",
    "    songs = [i.find_all(\"td\")[1].text.split(\"\\n\") for i in song_rows]\n",
    "    song_data_07.append(songs)\n",
    "#     df = pd.DataFrame(songs, columns = ['title', 'artist'])\n",
    "#     df['artist'] = df['artist'].str.replace(\" - tour dates\", \"\")\n",
    "\n",
    "songs_07 = get_data(url_07_list)\n",
    "\n",
    "songs_07[13]\n",
    "\n",
    "len(songs_07)\n",
    "\n",
    "df_07 = pd.DataFrame(columns= ['title', 'artist'])\n",
    "\n",
    "df_07\n",
    "\n",
    "## clean data\n",
    "# remove \" - tour dates \"\n",
    "df_07['artist'] = df_07['artist'].str.replace(\" - tour dates\", \"\")\n",
    "\n",
    "# strip extra white text from artist\n",
    "df_07['artist'] = df_07['artist'].str.strip()\n",
    "\n",
    "## export df_07\n",
    "df_07.to_csv('./data/2007.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2008 Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add date of pull to results\n",
    "- last 3 copies of website in 2008 are the same\n",
    "- 20080408070349 is not in same table but has data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now-playing for 2008\n",
    "# - only shows songs from 7am-9am? add query to url for all time?\n",
    "\n",
    "url_08 = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20080101&to=20081231&output=json\"\n",
    "\n",
    "# get request to the API for the text\n",
    "urls_08 = rq.get(url_08).text\n",
    "# parses json text from urls\n",
    "parse_url_08 = json.loads(urls_08)\n",
    "\n",
    "## compile url list- get timestamp and original columns from urls\n",
    "url_08_list = []\n",
    "for i in range(1, len(parse_url_08)):\n",
    "    orig_url = parse_url_08[i][2]\n",
    "    tstamp = parse_url_08[i][1]\n",
    "    waylink = tstamp+'/'+orig_url\n",
    "    url_08_list.append(waylink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1; Freq: 0.06949840716191977 requests/s\n",
      "Request: 2; Freq: 0.06633391774065908 requests/s\n",
      "Request: 3; Freq: 0.060269501248834664 requests/s\n",
      "Request: 4; Freq: 0.06423295275667996 requests/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [['Girlfriend', 'Bow Wow & Omarion - tour dates'],\n",
       "  ['Walk It Out', 'Unk & Outkast '],\n",
       "  ['Cyclone', 'BABY BASH/T-PAIN '],\n",
       "  ['BED', '                              J. HOLIDAY - tour dates'],\n",
       "  ['Temperature', 'Sean Paul '],\n",
       "  ['HATERZ', 'B.O.B./WES FIF - tour dates'],\n",
       "  ['Shawty', '                              PLIES/T-PAIN - tour dates'],\n",
       "  ['HATE THAT I LOVE YOU', '                              RIHANNA/NE-YO '],\n",
       "  ['Money Maker', 'Ludacris & Pharrell Williams '],\n",
       "  ['NO ONE', 'Alicia Keys '],\n",
       "  ['A Bay Bay', '                              HURRICANE CHRIS '],\n",
       "  ['Ghetto Superstar', 'Pras & Mya '],\n",
       "  ['KISS KISS', 'CHRIS BROWN/T-PAIN - tour dates'],\n",
       "  ['WHAT IS IT?', 'BABY BASH/SEAN KINGSTON '],\n",
       "  ['DUFFLE BAG BOY', '                              PLAYAZ CIRCLE/LIL WAYNE '],\n",
       "  ['Shortie Like Mine', 'Bow Wow & Chris Brown - tour dates'],\n",
       "  ['Low', 'FLO RIDA/T-PAIN '],\n",
       "  ['Confessions Pt. 2', 'Usher '],\n",
       "  ['CRANK THAT SOULJA BOY', '                              Soulja Boy '],\n",
       "  [\"I'M SO HOOD\", '                              DJ KHALED/PLIES '],\n",
       "  ['APOLOGIZE', 'TIMBALAND/ONE REPUBLIC '],\n",
       "  ['Kryptonite',\n",
       "   '                              Purple Ribbon Allstars & Outkast '],\n",
       "  ['Bartender', '                              T-PAIN/AKON '],\n",
       "  ['Stronger', 'Kanye West - tour dates'],\n",
       "  ['Sexyback', '                              JUSTIN TIMBERLAKE W/CLIPSE ']],\n",
       " [['Girlfriend', 'Bow Wow & Omarion - tour dates'],\n",
       "  ['Walk It Out', 'Unk & Outkast '],\n",
       "  ['Cyclone', 'BABY BASH/T-PAIN '],\n",
       "  ['BED', '                              J. HOLIDAY - tour dates'],\n",
       "  ['Temperature', 'Sean Paul '],\n",
       "  ['HATERZ', 'B.O.B./WES FIF - tour dates'],\n",
       "  ['Shawty', '                              PLIES/T-PAIN - tour dates'],\n",
       "  ['HATE THAT I LOVE YOU', '                              RIHANNA/NE-YO '],\n",
       "  ['Money Maker', 'Ludacris & Pharrell Williams '],\n",
       "  ['NO ONE', 'Alicia Keys '],\n",
       "  ['A Bay Bay', '                              HURRICANE CHRIS '],\n",
       "  ['Ghetto Superstar', 'Pras & Mya '],\n",
       "  ['KISS KISS', 'CHRIS BROWN/T-PAIN - tour dates'],\n",
       "  ['WHAT IS IT?', 'BABY BASH/SEAN KINGSTON '],\n",
       "  ['DUFFLE BAG BOY', '                              PLAYAZ CIRCLE/LIL WAYNE '],\n",
       "  ['Shortie Like Mine', 'Bow Wow & Chris Brown - tour dates'],\n",
       "  ['Low', 'FLO RIDA/T-PAIN '],\n",
       "  ['Confessions Pt. 2', 'Usher '],\n",
       "  ['CRANK THAT SOULJA BOY', '                              Soulja Boy '],\n",
       "  [\"I'M SO HOOD\", '                              DJ KHALED/PLIES '],\n",
       "  ['APOLOGIZE', 'TIMBALAND/ONE REPUBLIC '],\n",
       "  ['Kryptonite',\n",
       "   '                              Purple Ribbon Allstars & Outkast '],\n",
       "  ['Bartender', '                              T-PAIN/AKON '],\n",
       "  ['Stronger', 'Kanye West - tour dates'],\n",
       "  ['Sexyback', '                              JUSTIN TIMBERLAKE W/CLIPSE ']],\n",
       " [['Girlfriend', 'Bow Wow & Omarion - tour dates'],\n",
       "  ['Walk It Out', 'Unk & Outkast '],\n",
       "  ['Cyclone', 'BABY BASH/T-PAIN '],\n",
       "  ['BED', '                              J. HOLIDAY - tour dates'],\n",
       "  ['Temperature', 'Sean Paul '],\n",
       "  ['HATERZ', 'B.O.B./WES FIF - tour dates'],\n",
       "  ['Shawty', '                              PLIES/T-PAIN - tour dates'],\n",
       "  ['HATE THAT I LOVE YOU', '                              RIHANNA/NE-YO '],\n",
       "  ['Money Maker', 'Ludacris & Pharrell Williams '],\n",
       "  ['NO ONE', 'Alicia Keys '],\n",
       "  ['A Bay Bay', '                              HURRICANE CHRIS '],\n",
       "  ['Ghetto Superstar', 'Pras & Mya '],\n",
       "  ['KISS KISS', 'CHRIS BROWN/T-PAIN - tour dates'],\n",
       "  ['WHAT IS IT?', 'BABY BASH/SEAN KINGSTON '],\n",
       "  ['DUFFLE BAG BOY', '                              PLAYAZ CIRCLE/LIL WAYNE '],\n",
       "  ['Shortie Like Mine', 'Bow Wow & Chris Brown - tour dates'],\n",
       "  ['Low', 'FLO RIDA/T-PAIN '],\n",
       "  ['Confessions Pt. 2', 'Usher '],\n",
       "  ['CRANK THAT SOULJA BOY', '                              Soulja Boy '],\n",
       "  [\"I'M SO HOOD\", '                              DJ KHALED/PLIES '],\n",
       "  ['APOLOGIZE', 'TIMBALAND/ONE REPUBLIC '],\n",
       "  ['Kryptonite',\n",
       "   '                              Purple Ribbon Allstars & Outkast '],\n",
       "  ['Bartender', '                              T-PAIN/AKON '],\n",
       "  ['Stronger', 'Kanye West - tour dates'],\n",
       "  ['Sexyback', '                              JUSTIN TIMBERLAKE W/CLIPSE ']]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiles final url pattern\n",
    "song_data = []\n",
    "reqs = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for url in url_08_list:\n",
    "    \n",
    "    final_url_08 = 'https://web.archive.org/web/'+url\n",
    "    \n",
    "    try:\n",
    "        req=rq.get(final_url_08).text\n",
    "    except urllib.error.URLError as e:\n",
    "        print('Error: {}'.format(e.reason))\n",
    "        \n",
    "    sleep(randint(10,20))\n",
    "    reqs += 1\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print('Request: {}; Freq: {} requests/s'.format(reqs, reqs/elapsed_time))\n",
    "    \n",
    "    if reqs > len(url_08_list):\n",
    "        warn('No. of requests was greater than expected')\n",
    "        break\n",
    "    \n",
    "    soup = bs(req,'html.parser')\n",
    "    song_rows = soup.find_all(\"tr\", {\"height\": 32})\n",
    "    songs = [i.find_all(\"td\")[1].text.split(\"\\n\") for i in song_rows]\n",
    "    song_data.append(songs)\n",
    "#     df = pd.DataFrame(songs, columns = ['title', 'artist'])\n",
    "#     df['artist'] = df['artist'].str.replace(\" - tour dates\", \"\")\n",
    "song_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data_08 = song_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse html with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_rows = soup.find_all(\"tr\", {\"height\": 32})\n",
    "songs = [i.find_all(\"td\")[1].text.split(\"\\n\") for i in song_rows]\n",
    "\n",
    "# clean up output with update and map/filter once df has been madeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>Bow Wow &amp; Omarion - tour dates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walk It Out</td>\n",
       "      <td>Unk &amp; Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyclone</td>\n",
       "      <td>BABY BASH/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BED</td>\n",
       "      <td>J. HOLIDAY - tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                             artist\n",
       "0   Girlfriend                     Bow Wow & Omarion - tour dates\n",
       "1  Walk It Out                                     Unk & Outkast \n",
       "2      Cyclone                                  BABY BASH/T-PAIN \n",
       "3          BED                                J. HOLIDAY - tou...\n",
       "4  Temperature                                         Sean Paul "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(songs, columns = ['title', 'artist'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \" - tour dates \"\n",
    "df['artist'] = df['artist'].str.replace(\" - tour dates\", \"\")\n",
    "\n",
    "# strip extra white text from artist\n",
    "df['artist'] = df['artist'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>Bow Wow &amp; Omarion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walk It Out</td>\n",
       "      <td>Unk &amp; Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyclone</td>\n",
       "      <td>BABY BASH/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BED</td>\n",
       "      <td>J. HOLIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HATERZ</td>\n",
       "      <td>B.O.B./WES FIF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shawty</td>\n",
       "      <td>PLIES/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HATE THAT I LOVE YOU</td>\n",
       "      <td>RIHANNA/NE-YO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Money Maker</td>\n",
       "      <td>Ludacris &amp; Pharrell Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NO ONE</td>\n",
       "      <td>Alicia Keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A Bay Bay</td>\n",
       "      <td>HURRICANE CHRIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ghetto Superstar</td>\n",
       "      <td>Pras &amp; Mya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KISS KISS</td>\n",
       "      <td>CHRIS BROWN/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>WHAT IS IT?</td>\n",
       "      <td>BABY BASH/SEAN KINGSTON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DUFFLE BAG BOY</td>\n",
       "      <td>PLAYAZ CIRCLE/LIL WAYNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shortie Like Mine</td>\n",
       "      <td>Bow Wow &amp; Chris Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Low</td>\n",
       "      <td>FLO RIDA/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Confessions Pt. 2</td>\n",
       "      <td>Usher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CRANK THAT SOULJA BOY</td>\n",
       "      <td>Soulja Boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I'M SO HOOD</td>\n",
       "      <td>DJ KHALED/PLIES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>APOLOGIZE</td>\n",
       "      <td>TIMBALAND/ONE REPUBLIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Kryptonite</td>\n",
       "      <td>Purple Ribbon Allstars &amp; Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bartender</td>\n",
       "      <td>T-PAIN/AKON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Stronger</td>\n",
       "      <td>Kanye West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sexyback</td>\n",
       "      <td>JUSTIN TIMBERLAKE W/CLIPSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    title                            artist\n",
       "0              Girlfriend                 Bow Wow & Omarion\n",
       "1             Walk It Out                     Unk & Outkast\n",
       "2                 Cyclone                  BABY BASH/T-PAIN\n",
       "3                     BED                        J. HOLIDAY\n",
       "4             Temperature                         Sean Paul\n",
       "5                  HATERZ                    B.O.B./WES FIF\n",
       "6                  Shawty                      PLIES/T-PAIN\n",
       "7    HATE THAT I LOVE YOU                     RIHANNA/NE-YO\n",
       "8             Money Maker      Ludacris & Pharrell Williams\n",
       "9                  NO ONE                       Alicia Keys\n",
       "10              A Bay Bay                   HURRICANE CHRIS\n",
       "11       Ghetto Superstar                        Pras & Mya\n",
       "12              KISS KISS                CHRIS BROWN/T-PAIN\n",
       "13            WHAT IS IT?           BABY BASH/SEAN KINGSTON\n",
       "14         DUFFLE BAG BOY           PLAYAZ CIRCLE/LIL WAYNE\n",
       "15      Shortie Like Mine             Bow Wow & Chris Brown\n",
       "16                    Low                   FLO RIDA/T-PAIN\n",
       "17      Confessions Pt. 2                             Usher\n",
       "18  CRANK THAT SOULJA BOY                        Soulja Boy\n",
       "19            I'M SO HOOD                   DJ KHALED/PLIES\n",
       "20              APOLOGIZE            TIMBALAND/ONE REPUBLIC\n",
       "21             Kryptonite  Purple Ribbon Allstars & Outkast\n",
       "22              Bartender                       T-PAIN/AKON\n",
       "23               Stronger                        Kanye West\n",
       "24               Sexyback        JUSTIN TIMBERLAKE W/CLIPSE"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/102008sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
