{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scraping wayback machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "from time import time\n",
    "from random import randint\n",
    "from warnings import warn\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile list of urls w/ wayback server CDX API\n",
    "## http inlet that queries data from wayback machine \n",
    "### server responds to GET queries and outputs as JSON array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url anatomy\n",
    "# 'http://web.archive.org/cdx/search/cdx?url=nbcnews.com/politics&collapse=digest&from=20190401&to=20190431&output=json'\n",
    "## url= ____ from= to=  output=json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up CDX API query\n",
    "to-do: \n",
    "    - get different time window for request\n",
    "    - only pulled oct 14 2008?\n",
    "NOTE: html has updated from 2002-2008 to include ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE songs are listed from most recently played at top\n",
    "# display order is not same as table order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now-playing for 2002-2008\n",
    "# - only shows songs from 7am-9am? add query to url for all time?\n",
    "\n",
    "url = \"http://web.archive.org/cdx/search/cdx?url=http://955thebeat.com/includes/nowplaying/lsp/&from=20020101&to=20081231&output=json\"\n",
    "\n",
    "# get request to the API for the text\n",
    "urls = rq.get(url).text\n",
    "# parses json text from urls\n",
    "parse_url = json.loads(urls)\n",
    "\n",
    "## compile url list- get timestamp and original columns from urls\n",
    "url_list = []\n",
    "for i in range(1, len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)\n",
    "\n",
    "# compiles final url pattern\n",
    "for url in url_list:\n",
    "    final_url = 'https://web.archive.org/web/'+url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final url list is only last item, need to include the rest of the code in this for loop\n",
    "# when more urls are parsed, will need to update parsing code to include time/date data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse html with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open page to soupify\n",
    "req = rq.get(final_url).text\n",
    "\n",
    "# parse and store in soup\n",
    "soup = bs(req,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect page to look for id tags or other attributes -table with songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## move through parse tree with tag.contents and string\n",
    "# contents: ordered list of Tag and NavigableString objects in a page element\n",
    "# if tag has only one child node and it is a string:\n",
    "## tag.string or tag.contents[0]\n",
    "# .children    .next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_rows = soup.find_all(\"tr\", {\"height\": 32})\n",
    "songs = [i.find_all(\"td\")[1].text.split(\"\\n\") for i in song_rows]\n",
    "\n",
    "# clean up output with update and map/filter once df has been madeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>Bow Wow &amp; Omarion - tour dates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walk It Out</td>\n",
       "      <td>Unk &amp; Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyclone</td>\n",
       "      <td>BABY BASH/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BED</td>\n",
       "      <td>J. HOLIDAY - tou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                             artist\n",
       "0   Girlfriend                     Bow Wow & Omarion - tour dates\n",
       "1  Walk It Out                                     Unk & Outkast \n",
       "2      Cyclone                                  BABY BASH/T-PAIN \n",
       "3          BED                                J. HOLIDAY - tou...\n",
       "4  Temperature                                         Sean Paul "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(songs, columns = ['title', 'artist'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \" - tour dates \"\n",
    "df['artist'] = df['artist'].str.replace(\" - tour dates\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip extra white text from artist\n",
    "df['artist'] = df['artist'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Girlfriend</td>\n",
       "      <td>Bow Wow &amp; Omarion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walk It Out</td>\n",
       "      <td>Unk &amp; Outkast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cyclone</td>\n",
       "      <td>BABY BASH/T-PAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BED</td>\n",
       "      <td>J. HOLIDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Temperature</td>\n",
       "      <td>Sean Paul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title             artist\n",
       "0   Girlfriend  Bow Wow & Omarion\n",
       "1  Walk It Out      Unk & Outkast\n",
       "2      Cyclone   BABY BASH/T-PAIN\n",
       "3          BED         J. HOLIDAY\n",
       "4  Temperature          Sean Paul"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/102008sample.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
